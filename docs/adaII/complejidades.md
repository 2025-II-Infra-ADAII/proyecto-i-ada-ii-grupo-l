# Informe de Complejidad - Problema de Riego √ìptimo

## 1. Fuerza Bruta

---

### Complejidad Temporal T(n)

Para un conjunto de ( n ) tablones:

1. Generar todas las permutaciones posibles de los √≠ndices $0, 1, 2, \dots, n-1$ tiene un costo de: $O(n!)$
2. **Evaluaci√≥n del costo para cada permutaci√≥n:**
    
    La funci√≥n `compute_cost_for_permutation` recorre todos los tablones dos veces:
    
    - Una vez para calcular los tiempos de inicio $(O(n))$.
    - Otra vez para calcular el costo $(O(n))$.
    
    Por tanto, el costo de evaluar una permutaci√≥n es:
    
    $$
    (O(n))
    $$
    
3. **Costo total del algoritmo:**

$$
O(n! \times n) = O(n \cdot n!)
$$

### üîπ Ejemplo de crecimiento

| n | $n!$   | $n¬∑n!$ (operaciones aproximadas) |
| --- |--------|----------------------------------|
| 4 | 24     | 96                               |
| 6 | 720    | 4320                             |
| 8 | 40320  | 322560                           |
| 10 | 3.6√ó10‚Å∂ | 3.6√ó10‚Å∑                          |

El crecimiento factorial vuelve al algoritmo **inviable para n mayores a 10**, pues el tiempo de ejecuci√≥n crece exponencialmente.

### Complejidad Espacial S(n)

- Cada permutaci√≥n se genera y procesa una a la vez por `itertools.permutations`, lo que evita almacenar todas las permutaciones en memoria.
- Se usa memoria proporcional a:
    - La lista `finca` ‚Üí (O(n))
    - La lista temporal `perm` ‚Üí (O(n))
    - Variables auxiliares (enteros, listas temporales peque√±as)

Por tanto:

$$
\text{Complejidad espacial } = O(n)
$$

### Correcci√≥n del algoritmo

El m√©todo de fuerza bruta **garantiza la soluci√≥n √≥ptima**, ya que explora exhaustivamente **todas las posibles permutaciones** del orden de riego y selecciona la de menor costo.

Formalmente:

$$
\text{roFB}(F) = \arg\min_{\Pi \in S_n} CRF_{\Pi}
$$

donde $S_n$ es el conjunto de todas las permutaciones de $n$ elementos.

Por lo tanto, el algoritmo es **correcto y completo**, aunque **ineficiente para grandes valores de $n$**.

## 2. Programaci√≥n Din√°mica

## Complejidad Temporal T(n)

- $S$ tiene una cantidad $2^n$  de subconjuntos posibles dado por las `mask` .
- Para cada subconjunto se itera sobre los tablones activos.
- Para cada tabl√≥n se busca tomar su tiempo, donde en el peor caso puede haber varios pero el n√∫mero total de estados `(mask)` crece proporcionalmente al n√∫mero de combinaciones distintas.

Teniendo esto en cuenta, la complejidad T(n) de la soluci√≥n din√°mica es de:

$$
T(n) = O(n*2^n)
$$

## Complejidad Espacial S(n)

- En memoria se almacena un valor $DP[S]$ por cada conjunto $S$
- $DP$ guarda al menos un valor por cada combinaci√≥n posible de `(mask, t)`

Por lo tanto, la complejidad espacial S(n) es de:

$$
S(n) = O(2^n)
$$

---

# 3. Algoritmo Voraz

---

## Complejidad Temporal T(n)

- El algoritmo inicia calculando una **raz√≥n de prioridad** `(p·µ¢ / ts·µ¢)` para cada tabl√≥n, operaci√≥n que se realiza una sola vez por elemento, en tiempo **O(n)**.
- Luego, utiliza la funci√≥n `sorted()` de Python para **ordenar los tablones** seg√∫n dicha raz√≥n.
El algoritmo de ordenamiento m√°s eficiente empleado por Python (Timsort) tiene una complejidad temporal de **O(n log n)**.
- Finalmente, se realiza un recorrido lineal sobre todos los tablones para **calcular el costo total**, lo cual a√±ade un costo adicional **O(n)**.

Sumando todos los pasos, la complejidad temporal del algoritmo voraz es:

$$
T(n) = O(n \log n)
$$

Esto significa que el algoritmo escala de manera eficiente, incluso para **instancias grandes**, manteniendo tiempos de ejecuci√≥n muy bajos comparados con los m√©todos de fuerza bruta o programaci√≥n din√°mica.

---

## Complejidad Espacial S(n)

- El algoritmo utiliza una **lista de √≠ndices** de tama√±o *n* para representar el orden de riego.
- No requiere estructuras adicionales de almacenamiento, ni matrices de estados o m√°scaras.
- Las variables empleadas (`tiempo_actual`, `costo_total`, `orden`) ocupan **espacio constante** adicional.

Por lo tanto, la complejidad espacial es lineal con respecto al n√∫mero de tablones:

$$
S(n) = O(n)
$$

Esto hace que el algoritmo voraz sea **muy eficiente en uso de memoria**, apropiado para resolver problemas de gran escala con recursos limitados.

---

## 4. Resumen comparativo

| Estrategia            | Complejidad temporal | Complejidad espacial                   |
| --------------------- | -------------------- | -------------------------------------- |
| Fuerza bruta          | $\(O(n \cdot 2^n)\)$   | $\(O(n)\)$                               |
| Programaci√≥n din√°mica | $\(O(n \cdot W)\) $    | $\(O(n \cdot W)\) √≥ \(O(W)\)$ optimizado |
| Voraz                 | $\(O(n \log n)\) $    | $\(O(n)\)$                               |

---

### 4.1 Analisis mediante gr√°ficas

Comparacion teorica de complejidades en tiempo y espacio para las tres estrategias implementadas.

![Comparativa de tiempo](imagenes/g1.png)

Analisis de DP con W con n fijo

![Comparativa DP](imagenes/g2.png)

Recordar incluir la comparacion de tiempos con respecto a lo implementado. No se incluye en este ejemplo.


Comparacion teorica de complejidades en caso practico y teorico de PD.

|[Comparativa complejidad](imagenes/PD1.png)

---

## 5. Conclusiones

### Programaci√≥n bruta:

La soluci√≥n por fuerza bruta genera todas las permutaciones posibles, por lo tanto su complejidad temporal es
$O(n!‚ãÖn)$.
Se verific√≥ experimentalmente que el tiempo crece factorialmente: la ejecuci√≥n es factible hasta $n=10$.
Para n mayores, el algoritmo resulta impracticable: por ejemplo, $n=100$ implicar√≠a 9.3√ó10¬π‚Åµ‚Å∑ permutaciones, lo que hace imposible su ejecuci√≥n en cualquier computador actual.
El enfoque de fuerza bruta sirve como **referencia base** para comparar las soluciones **voraces** y de **programaci√≥n din√°mica**, permitiendo verificar la correcci√≥n de sus resultados.

### Programaci√≥n din√°mica:

En el punto de vista del costo computacional un costo de $O(n*2^n)$ hace que para tama√±os peque√±os de tablones sea mucho m√°s eficiente que la solucion bruta, sin embargo, cuando $numeroTablones > 20$, entonces el tiempo crece tanto que resulta inviable y casi imposible de calcular.

### Programaci√≥n voraz:

El enfoque voraz demostr√≥ ser **el m√°s eficiente en tiempo de ejecuci√≥n**, con una complejidad de $O(n \log n)$, lo que le permite manejar f√°cilmente instancias grandes del problema.

Aunque no siempre garantiza la **soluci√≥n √≥ptima**, los resultados obtenidos fueron **cercanos al √≥ptimo** en la mayor√≠a de los casos, mostrando un **buen equilibrio entre precisi√≥n y eficiencia**.

Su simplicidad y bajo costo computacional la convierten en una estrategia pr√°ctica para situaciones donde la rapidez es prioritaria sobre la exactitud total.